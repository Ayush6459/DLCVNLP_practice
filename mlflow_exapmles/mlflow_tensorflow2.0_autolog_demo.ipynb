{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8fd962b",
   "metadata": {},
   "source": [
    "## Using autolog \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17f3e0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (Flatten)        (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer_1 (Dense)       (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "hidden_layer_2 (Dense)       (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "hidden_layer_3 (Dense)       (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 573,910\n",
      "Trainable params: 573,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc8f83fc950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc8f83fc950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "   2/1719 [..............................] - ETA: 53s - loss: 2.3916 - accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0058s vs `on_train_batch_end` time: 0.0559s). Check your callbacks.\n",
      "1706/1719 [============================>.] - ETA: 0s - loss: 1.0572 - accuracy: 0.6540WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fc8d69253b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fc8d69253b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 1.0545 - accuracy: 0.6544 - val_loss: 0.6500 - val_accuracy: 0.7602\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.6191 - accuracy: 0.7736 - val_loss: 0.6073 - val_accuracy: 0.7642\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.5486 - accuracy: 0.8007 - val_loss: 0.5088 - val_accuracy: 0.8200\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.5086 - accuracy: 0.8137 - val_loss: 0.4860 - val_accuracy: 0.8248\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4808 - accuracy: 0.8255 - val_loss: 0.4620 - val_accuracy: 0.8388\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4619 - accuracy: 0.8333 - val_loss: 0.4546 - val_accuracy: 0.8404\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4450 - accuracy: 0.8397 - val_loss: 0.4383 - val_accuracy: 0.8468\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4346 - accuracy: 0.8433 - val_loss: 0.4200 - val_accuracy: 0.8546\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.4228 - accuracy: 0.8479 - val_loss: 0.4166 - val_accuracy: 0.8572\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4145 - accuracy: 0.8505 - val_loss: 0.4360 - val_accuracy: 0.8470\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fc8cbdf2200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fc8cbdf2200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: /var/folders/xw/qnpfprsd1vd47scxmvgqw4kw0000gn/T/tmp84in7d2g/model/data/model/assets\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc8cc1f5710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fc8cc1f5710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4696 - accuracy: 0.8304\n",
      "0.8303999900817871\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import mlflow\n",
    "\n",
    "# load the dataset\n",
    "(X_train_full , y_train_full),(X_test,y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# create validation set \n",
    "# and normalise the dataset\n",
    "X_valid ,X_train = X_train_full[:5000]/255,X_train_full[5000:]/255\n",
    "y_valid ,y_train = y_train_full[:5000] , y_train_full[5000:]\n",
    "X_test=X_test/255\n",
    "\n",
    "# define the lalyers \n",
    "Layers =[\n",
    "        tf.keras.layers.Flatten(input_shape=[28,28],name=\"input_layer\"),\n",
    "        tf.keras.layers.Dense(500,activation='sigmoid',name='hidden_layer_1'),\n",
    "        tf.keras.layers.Dense(300,activation='relu',name=\"hidden_layer_2\"),\n",
    "        tf.keras.layers.Dense(100,activation='relu',name=\"hidden_layer_3\"),\n",
    "        tf.keras.layers.Dense(10,activation='softmax',name=\"output_layer\")\n",
    "]\n",
    "\n",
    "# initialies the model\n",
    "model = tf.keras.models.Sequential(Layers)\n",
    "model.summary()\n",
    "# compile the model\n",
    "Loss_fun = 'sparse_categorical_crossentropy'\n",
    "Optimizers = \"SGD\"\n",
    "Metrics = [\"accuracy\"]\n",
    "model.compile(optimizer=Optimizers,loss=Loss_fun,metrics=Metrics)\n",
    "\n",
    "# run mlflow autolog \n",
    "\n",
    "mlflow.tensorflow.autolog()\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model.fit(X_train,y_train,epochs=10,validation_data=(X_valid,y_valid),verbose=1)\n",
    "    preds=model.predict(X_test)\n",
    "    preds=np.round(preds)\n",
    "    eval_acc=model.evaluate(X_test,y_test)[1]\n",
    "    print(eval_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "294a79a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-06-10 22:37:46 +0530] [38790] [INFO] Starting gunicorn 20.0.4\n",
      "[2021-06-10 22:37:46 +0530] [38790] [INFO] Listening at: http://127.0.0.1:5000 (38790)\n",
      "[2021-06-10 22:37:46 +0530] [38790] [INFO] Using worker: sync\n",
      "[2021-06-10 22:37:46 +0530] [38793] [INFO] Booting worker with pid: 38793\n",
      "^C\n",
      "[2021-06-10 22:38:06 +0530] [38790] [INFO] Handling signal: int\n",
      "[2021-06-10 22:38:06 +0530] [38793] [INFO] Worker exiting (pid: 38793)\n"
     ]
    }
   ],
   "source": [
    "!mlflow ui\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825191ff",
   "metadata": {},
   "source": [
    "# Custom logging example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c769df17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(activation_fun):\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import mlflow\n",
    "    from tensorflow.keras.datasets import fashion_mnist\n",
    "    \n",
    "    # load the dataset\n",
    "    (X_train_full , y_train_full),(X_test,y_test) = fashion_mnist.load_data()\n",
    "\n",
    "    # create validation set \n",
    "    # and normalise the dataset\n",
    "    X_valid ,X_train = X_train_full[:5000]/255,X_train_full[5000:]/255\n",
    "    y_valid ,y_train = y_train_full[:5000] , y_train_full[5000:]\n",
    "    X_test=X_test/255\n",
    "    \n",
    "    activation_fun = activation_fun\n",
    "    \n",
    "    # define the lalyers \n",
    "    Layers =[\n",
    "            tf.keras.layers.Flatten(input_shape=[28,28],name=\"input_layer\"),\n",
    "            tf.keras.layers.Dense(500,activation=activation_fun,name='hidden_layer_1'),\n",
    "            tf.keras.layers.Dense(300,activation=activation_fun,name=\"hidden_layer_2\"),\n",
    "            tf.keras.layers.Dense(100,activation=activation_fun,name=\"hidden_layer_3\"),\n",
    "            tf.keras.layers.Dense(10,activation='softmax',name=\"output_layer\")\n",
    "    ]\n",
    "    \n",
    "    model = tf.keras.models.Sequential(Layers)\n",
    "    model.summary()\n",
    "    \n",
    "    # compile the model\n",
    "    Loss_fun = 'sparse_categorical_crossentropy'\n",
    "    Optimizers = \"SGD\"\n",
    "    Metrics = [\"accuracy\"]\n",
    "    model.compile(optimizer=Optimizers,loss=Loss_fun,metrics=Metrics)\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        model.fit(X_train,y_train,epochs=10,validation_data=(X_valid,y_valid),verbose=1)\n",
    "        preds=model.predict(X_test)\n",
    "        preds=np.round(preds)\n",
    "        eval_acc=model.evaluate(X_test,y_test)[1]\n",
    "        print(eval_acc)\n",
    "        \n",
    "        mlflow.log_param(\"activation_fun\",activation_fun)\n",
    "        mlflow.log_param('Loss_fun',Loss_fun)\n",
    "        mlflow.log_param('Optimizers',Optimizers)\n",
    "        mlflow.log_metric('eval_acc',eval_acc)\n",
    "        #mlflow.tensorflow.log_model(model,\"models\")\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "750c3502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (Flatten)        (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer_1 (Dense)       (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "hidden_layer_2 (Dense)       (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "hidden_layer_3 (Dense)       (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 573,910\n",
      "Trainable params: 573,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa8cbdb0dd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa8cbdb0dd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1718/1719 [============================>.] - ETA: 0s - loss: 0.7099 - accuracy: 0.7643WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa8cb96c9e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa8cb96c9e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.7099 - accuracy: 0.7643 - val_loss: 0.4985 - val_accuracy: 0.8252\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 0.4724 - accuracy: 0.8328 - val_loss: 0.4100 - val_accuracy: 0.8654\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 9s 6ms/step - loss: 0.4223 - accuracy: 0.8497 - val_loss: 0.3966 - val_accuracy: 0.8582\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3906 - accuracy: 0.8615 - val_loss: 0.3775 - val_accuracy: 0.8682\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3686 - accuracy: 0.8694 - val_loss: 0.3607 - val_accuracy: 0.8752\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3502 - accuracy: 0.8738 - val_loss: 0.3484 - val_accuracy: 0.8768\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.3358 - accuracy: 0.8801 - val_loss: 0.3597 - val_accuracy: 0.8718\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 15s 8ms/step - loss: 0.3240 - accuracy: 0.8842 - val_loss: 0.3334 - val_accuracy: 0.8824\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3121 - accuracy: 0.8869 - val_loss: 0.3305 - val_accuracy: 0.8810\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3025 - accuracy: 0.8907 - val_loss: 0.3190 - val_accuracy: 0.8856\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa89bf4d4d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa89bf4d4d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3536 - accuracy: 0.8757: 0s - loss: 0.3635 - accu\n",
      "0.8756999969482422\n"
     ]
    }
   ],
   "source": [
    "train_model('relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "369148c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-06-11 09:25:06 +0530] [7706] [INFO] Starting gunicorn 20.0.4\n",
      "[2021-06-11 09:25:06 +0530] [7706] [INFO] Listening at: http://127.0.0.1:5000 (7706)\n",
      "[2021-06-11 09:25:06 +0530] [7706] [INFO] Using worker: sync\n",
      "[2021-06-11 09:25:06 +0530] [7709] [INFO] Booting worker with pid: 7709\n",
      "^C\n",
      "[2021-06-11 09:25:44 +0530] [7706] [INFO] Handling signal: int\n",
      "[2021-06-11 09:25:45 +0530] [7709] [INFO] Worker exiting (pid: 7709)\n"
     ]
    }
   ],
   "source": [
    "!mlflow ui\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0ae3ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbaseconda96d6f791f7a948bea67cd3c890e8b7fb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
